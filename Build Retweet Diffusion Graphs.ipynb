{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystache, plotly, json, random, sys, yaml, glob, os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates Interactive Diffusion Graphs\n",
    "\n",
    "1. Reads yaml configuration files from `/home/jupyter/data/www/covid19-static-pages/configs`\n",
    "2. Queries for retweets from Big Query\n",
    "3. Processes and produces simplified JSON output of retweets.\n",
    "3. Reads simplified JSON into Plotly and writes JSON configurations for Plotly Graphs and HTML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    '/home/jupyter/covid-19-data/.credentials/google-connector.json')\n",
    "project_id = 'crypto-eon-164220'\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get top retweets from Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_N_retweeted_tweets(table, N=25):\n",
    "    sys.stderr.write(\"Querying for top {} retweets in {}...\".format(N, table))\n",
    "    \n",
    "    query_job = client.query(\"\"\"\n",
    "SELECT\n",
    "  id AS retweet_id,\n",
    "  min(original_tweet_id) AS orig_id,\n",
    "  min(tweet_text) AS orig_text,\n",
    "  min(source) AS source,\n",
    "  min(times_retweeted_) AS times_retweeted,\n",
    "  min(original_author) AS orig_author,\n",
    "  min(original_followers) as orig_followers_count,\n",
    "  min(original_posted) AS orig_posted,\n",
    "  min(user.screen_name) AS retweeter,\n",
    "  min(user.followers_count) AS retweeter_followers_count,\n",
    "  min(PARSE_TIMESTAMP('%a %b %d %T %z %Y', created_at)) AS retweet_timestamp\n",
    "FROM\n",
    "  `crypto-eon-164220.tweets.{TABLE}` tweets,\n",
    "  (\n",
    "  SELECT\n",
    "    MIN(retweeted_status.id) AS original_tweet_id,\n",
    "    MIN(retweeted_status.text) AS tweet_text,\n",
    "    MIN(retweeted_status.user.screen_name) AS original_author,\n",
    "    MIN(retweeted_status.user.followers_count) AS original_followers,\n",
    "    MIN(PARSE_TIMESTAMP('%a %b %d %T %z %Y', retweeted_status.created_at)) AS original_posted,\n",
    "    COUNT(DISTINCT(id)) AS times_retweeted_\n",
    "  FROM\n",
    "    `crypto-eon-164220.tweets.{TABLE}`\n",
    "  WHERE\n",
    "    retweeted_status IS NOT NULL\n",
    "    AND retweeted_status.id >= (SELECT MIN(id) FROM `crypto-eon-164220.tweets.{TABLE}`)\n",
    "  GROUP BY\n",
    "    retweeted_status.id\n",
    "  ORDER BY times_retweeted_ DESC\n",
    "  LIMIT {N}\n",
    "  ) topRetweets\n",
    "WHERE\n",
    "  topRetweets.original_tweet_id = tweets.retweeted_status.id\n",
    "GROUP by id\n",
    "order by orig_id\n",
    "\"\"\".format(TABLE=table,\n",
    "           N=N) )\n",
    "    \n",
    "    sys.stderr.write(\"done; creating dataframe\\n\")\n",
    "    return query_job.result().to_dataframe()\n",
    "\n",
    "def get_tweets_retweeted_more_than_X_times(table, threshold=2000):\n",
    "    sys.stderr.write(\"Querying for tweets retweeted more than {} times in {}...\".format(threshold, table))\n",
    "    \n",
    "    query_job = client.query(\"\"\"\n",
    "SELECT\n",
    "  id AS retweet_id,\n",
    "  min(original_tweet_id) AS orig_id,\n",
    "  min(tweet_text) AS orig_text,\n",
    "  min(times_retweeted_) AS times_retweeted,\n",
    "  min(original_author) AS orig_author,\n",
    "  min(original_followers) as orig_followers_count,\n",
    "  min(original_posted) AS orig_posted,\n",
    "  min(user.screen_name) AS retweeter,\n",
    "  min(user.followers_count) AS retweeter_followers_count,\n",
    "  min(PARSE_TIMESTAMP('%a %b %d %T %z %Y', created_at)) AS retweet_timestamp\n",
    "FROM\n",
    "  `crypto-eon-164220.tweets.{TABLE}` tweets,\n",
    "  (\n",
    "  SELECT\n",
    "    MIN(retweeted_status.id) AS original_tweet_id,\n",
    "    MIN(retweeted_status.text) AS tweet_text,\n",
    "    MIN(retweeted_status.user.screen_name) AS original_author,\n",
    "    MIN(retweeted_status.user.followers_count) AS original_followers,\n",
    "    MIN(PARSE_TIMESTAMP('%a %b %d %T %z %Y', retweeted_status.created_at)) AS original_posted,\n",
    "    COUNT(DISTINCT(id)) AS times_retweeted_\n",
    "  FROM\n",
    "    `crypto-eon-164220.tweets.{TABLE}`\n",
    "  WHERE\n",
    "    retweeted_status IS NOT NULL\n",
    "    AND retweeted_status.id >= (SELECT MIN(id) FROM `crypto-eon-164220.tweets.{TABLE}`)\n",
    "  GROUP BY\n",
    "    retweeted_status.id\n",
    "  ORDER BY times_retweeted_ DESC\n",
    "  ) topRetweets\n",
    "WHERE\n",
    "  topRetweets.original_tweet_id = tweets.retweeted_status.id\n",
    "  AND topRetweets.times_retweeted_ > {TIMES_RETWEETED_THRESHOLD} \n",
    "GROUP by id\n",
    "order by orig_id\n",
    "\"\"\".format(TABLE=table,\n",
    "           TIMES_RETWEETED_THRESHOLD=threshold) )\n",
    "    \n",
    "    sys.stderr.write(\"done; creating dataframe\\n\")\n",
    "    return query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_for_plotly(df, fileName):\n",
    "\n",
    "    retweet_counts_by_id = list(df.orig_id.value_counts(ascending=False).keys())\n",
    "\n",
    "    count = 0;\n",
    "    to_return = pd.DataFrame()\n",
    "\n",
    "    for original_id, retweets in df.groupby('orig_id'):\n",
    "        count += 1;\n",
    "        topN = retweet_counts_by_id.index(original_id) + 1 # The Top N tweet...\n",
    "        print(\"Processing Tweet# {} - TopN [{}] - ID: {})\".format(count, topN, original_id))\n",
    "\n",
    "        sorted_retweets = retweets.sort_values(by='retweet_id').reindex()\n",
    "\n",
    "        original_tweet = pd.DataFrame([{\n",
    "            'id': sorted_retweets.iloc[0].orig_id,\n",
    "            'created_at': sorted_retweets.iloc[0].orig_posted,\n",
    "            'username': sorted_retweets.iloc[0].orig_author,\n",
    "            'followers_count': sorted_retweets.iloc[0].orig_followers_count\n",
    "        }])\n",
    "\n",
    "        text = sorted_retweets.iloc[0].orig_text\n",
    "\n",
    "        interested_rows = sorted_retweets[['retweet_id','retweet_timestamp','retweeter','retweeter_followers_count','source']]\n",
    "        interested_rows.columns = ['id','created_at','username','followers_count','source']\n",
    "\n",
    "        #Add the first row for the original tweet\n",
    "        x = pd.concat([original_tweet, interested_rows]).reset_index(drop = True) \n",
    "\n",
    "        x['followers_count_cumsum'] = x.followers_count.cumsum()\n",
    "        x['text'] = text\n",
    "        x['top_N'] = topN\n",
    "        \n",
    "        x.created_at = x.created_at.apply(lambda x: x.isoformat())\n",
    "\n",
    "        to_return = pd.concat([x, to_return])\n",
    "\n",
    "    current_datestamp = datetime.today().strftime('%Y-%m-%d')\n",
    "    with open(fileName +\"_\"+current_datestamp+'.json','w') as f:\n",
    "        json.dump(to_return.sort_values(by='top_N').to_dict('records'), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(config):\n",
    "    \n",
    "    df = get_top_N_retweeted_tweets(config['table'], N= (config.get(\"topN\") or 10) )\n",
    "    \n",
    "    create_dataframe_for_plotly(df, config['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = plotly.colors.qualitative.Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_colors():\n",
    "    sns.palplot(COLORS)\n",
    "\n",
    "def normalize(values, desired_bounds):\n",
    "    actual_bounds = (min(values), max(values))\n",
    "    result = [desired_bounds[0] + (x - actual_bounds[0]) *\n",
    "            (desired_bounds[1] - desired_bounds[0]) / \\\n",
    "            (actual_bounds[1] - actual_bounds[0]) for x in values]\n",
    "    return [round(x,2) for x in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the latest diffusion data...\n",
    "def read_dataframe_from_file(CONFIG):\n",
    "\n",
    "    #Get the latest file\n",
    "    latest_file = sorted(glob.glob(CONFIG['data']+\"*.json\"))[-1]\n",
    "    \n",
    "    sys.stderr.write(\"Loading \"+latest_file+\"...\")\n",
    "    to_plot = json.load(open(latest_file,'r')) #Could put error handling here if necessary\n",
    "\n",
    "    df = pd.DataFrame(to_plot)\n",
    "    df['timestamp'] = df.created_at.apply(lambda t: pd.Timestamp(t))\n",
    "    sys.stderr.write((\"Read {:,} retweets\\n\".format(len(to_plot))))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_self_retweets(input_df):\n",
    "\n",
    "    sys.stderr.write(\"Discounting self-retweets: [\")\n",
    "    df = pd.DataFrame.copy(input_df, deep=True)\n",
    "    \n",
    "    tweet_data = {}\n",
    "\n",
    "    for topN in df.top_N.unique():\n",
    "        newCounter = 0\n",
    "        subValue = 0\n",
    "        for idx, row in df[df.top_N == topN].sort_values(by='id').iterrows():\n",
    "            if newCounter==0:\n",
    "                thisUser = row.username\n",
    "                origFollowerCount = row.followers_count\n",
    "                origTweetID = str(row.id)\n",
    "                tweet_data[str(topN)] = {\n",
    "                    'text' : row.text,\n",
    "                    'user' : thisUser,\n",
    "                    'rank' : int(topN),\n",
    "                    'color': COLORS[topN%len(COLORS)],\n",
    "                    'id'   : origTweetID,\n",
    "                    'self-rt' : [],\n",
    "                    'time' : row.timestamp.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                if row.username == thisUser:\n",
    "                    if row.followers_count > origFollowerCount:\n",
    "                        subValue = origFollowerCount\n",
    "                    else:\n",
    "                        subValue = row.followers_count\n",
    "                    tweet_data[str(topN)]['self-rt'].append(\n",
    "#                         \"2020-04-19T01:53:07+00:00\"\n",
    "                        {'x':row.timestamp.isoformat(), 'subValue':subValue}\n",
    "                    )                    \n",
    "            if subValue > 0:\n",
    "                df.loc[idx,'followers_count_cumsum'] = row.followers_count_cumsum - subValue\n",
    "            newCounter += 1;\n",
    "        sys.stderr.write(\"{},\".format(topN))\n",
    "        \n",
    "    sys.stderr.write(\"] done\\n\".format(topN))\n",
    "    \n",
    "    return (df, tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_label(row):\n",
    "    return \"{}: {} followers\".format(row.username, row.followers_count)\n",
    "\n",
    "def buildPlotlyGraph(df, topN=25):\n",
    "    sys.stderr.write(\"Plotting top {} [\".format(topN))\n",
    "    \n",
    "#     df['globalScaledMarker'] = df.followers_count.apply(lambda x: np.log2(x+1))\n",
    "    df['globalScaledMarker'] = normalize(list(df.followers_count), (10,100))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for topNidx in range(1,topN+1):\n",
    "\n",
    "        #Should be sorted safely?\n",
    "        plot_df = df[df.top_N==topNidx].sort_values(by='id')\n",
    "\n",
    "        if len(plot_df) > 0:\n",
    "\n",
    "            tweetId   = str(plot_df.head(1).id.values[0])\n",
    "            tweetText = plot_df.head(1).text.values[0]\n",
    "\n",
    "            if pd.isna(tweetText):\n",
    "                raise \"No Tweet Text on First Entry\"\n",
    "\n",
    "            color = COLORS[topNidx%len(COLORS)]\n",
    "\n",
    "            fig.add_trace(go.Scattergl(\n",
    "                name = str(topNidx), #rank\n",
    "                x    = plot_df.timestamp, \n",
    "                y    = plot_df.followers_count_cumsum,\n",
    "                mode = 'markers+lines',\n",
    "                marker = dict(\n",
    "                    size  = plot_df.globalScaledMarker, #normalize(list(plot_df.followers_count), (10,35)),\n",
    "                    color = color,\n",
    "                    opacity = 0.5,\n",
    "                    line=dict(\n",
    "                        color='white',\n",
    "                        width=0.4\n",
    "                    ),\n",
    "                ),\n",
    "                line=dict(\n",
    "                    color=color,\n",
    "                    width=0.75,\n",
    "                ),\n",
    "                hovertemplate ='%{x} - %{text}',\n",
    "                text = list(plot_df.apply(lambda row: custom_label(row), axis=1)),\n",
    "                meta={'u':plot_df.username,\n",
    "                      'f':plot_df.followers_count },\n",
    "                showlegend = True\n",
    "            ))\n",
    "            sys.stderr.write(\".\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1400,\n",
    "        height=600,\n",
    "        margin=dict(\n",
    "            t=1,r=50,l=1,b=1\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            traceorder=\"normal\",\n",
    "            font=dict(\n",
    "                family=\"sans-serif\",\n",
    "                size=12,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "    ),\n",
    "        yaxis_title=\"Potential Audience Exposure\",)\n",
    "\n",
    "    sys.stderr.write(\"] Done\\n\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For testing (initialize all below functions first (ah, jupyter)): \n",
    "# # c = full_run('/home/jupyter/data/www/covid19-static-pages/configs/cdc.yaml', query=False)\n",
    "\n",
    "# # Then change the function as much as needed and access with:\n",
    "# fig = buildPlotlyGraph(c['no_self_retweets'], (c.get('TopN') or 25))\n",
    "# # fig.show()\n",
    "\n",
    "# #Or write the JSON\n",
    "# figJSON = json.loads(plotly.io.to_json(fig))\n",
    "# figJSON['tweets'] = c['tweets']\n",
    "# with open(STATIC_PAGES_ROOT +\"/docs/\"+ c['JSON'],'w') as outFile: \n",
    "#     json.dump(figJSON, outFile)\n",
    "# buildSingleStaticPlotlyPage(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSingleStaticPlotlyPage(CONFIG):\n",
    "    sys.stderr.write(\"Writing HTML... \")\n",
    "\n",
    "    main_template = open(STATIC_PAGES_ROOT + '/templates/plotly_js_template.html').read()\n",
    "\n",
    "    with open(STATIC_PAGES_ROOT + \"/\" + CONFIG['output'],'w') as outFile:\n",
    "        outFile.write(pystache.render(main_template, CONFIG))\n",
    "    sys.stderr.write(\" view at: http://epic.tweetsonamap.com/covid19-static-pages/\"+CONFIG['output']+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES?\n",
    "STATIC_PAGES_ROOT = '/home/jupyter/data/www/covid19-static-pages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_run(yaml_config, query=True, plot=True, write_html=True):\n",
    "    print(\"Building page for: {}\".format(yaml_config))\n",
    "    config = yaml.load(open(yaml_config,'r'),\n",
    "                       Loader=yaml.FullLoader)\n",
    "    \n",
    "    if query:\n",
    "        get_data(config)\n",
    "    \n",
    "    if plot:\n",
    "        config['df'] = read_dataframe_from_file(config)\n",
    "    \n",
    "        topN = config.get('topN') or 25\n",
    "    \n",
    "        config['no_self_retweets'], config['tweets'] = calculate_self_retweets(config['df'] )\n",
    "\n",
    "        config['fig'] = buildPlotlyGraph(config['no_self_retweets'], topN=topN)\n",
    "    \n",
    "        figJSON = json.loads(plotly.io.to_json(config['fig']))\n",
    "        figJSON['tweets'] = config['tweets']\n",
    "        \n",
    "        with open(STATIC_PAGES_ROOT +\"/docs/\"+ config['JSON'],'w') as outFile: \n",
    "            json.dump(figJSON, outFile)\n",
    "            \n",
    "    if write_html:\n",
    "        buildSingleStaticPlotlyPage(config)\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/cdc.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying for top 25 retweets in cdc_userstreams...done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [24] - ID: 1251617761639489536)\n",
      "Processing Tweet# 2 - TopN [3] - ID: 1252632573798473731)\n",
      "Processing Tweet# 3 - TopN [11] - ID: 1252993080174796800)\n",
      "Processing Tweet# 4 - TopN [8] - ID: 1253085285161803777)\n",
      "Processing Tweet# 5 - TopN [6] - ID: 1253341609443250176)\n",
      "Processing Tweet# 6 - TopN [15] - ID: 1253374836317044736)\n",
      "Processing Tweet# 7 - TopN [2] - ID: 1253422154256756738)\n",
      "Processing Tweet# 8 - TopN [13] - ID: 1253468948068290560)\n",
      "Processing Tweet# 9 - TopN [14] - ID: 1253705772569067520)\n",
      "Processing Tweet# 10 - TopN [1] - ID: 1253742258853199872)\n",
      "Processing Tweet# 11 - TopN [7] - ID: 1253793094841090056)\n",
      "Processing Tweet# 12 - TopN [10] - ID: 1253818998942314496)\n",
      "Processing Tweet# 13 - TopN [18] - ID: 1254129055219298308)\n",
      "Processing Tweet# 14 - TopN [17] - ID: 1254857606859898881)\n",
      "Processing Tweet# 15 - TopN [20] - ID: 1255971941019762694)\n",
      "Processing Tweet# 16 - TopN [5] - ID: 1256309675269615616)\n",
      "Processing Tweet# 17 - TopN [22] - ID: 1256655451195715585)\n",
      "Processing Tweet# 18 - TopN [25] - ID: 1257385261169860608)\n",
      "Processing Tweet# 19 - TopN [16] - ID: 1261044372621189120)\n",
      "Processing Tweet# 20 - TopN [9] - ID: 1261406011039993856)\n",
      "Processing Tweet# 21 - TopN [19] - ID: 1262052014973911041)\n",
      "Processing Tweet# 22 - TopN [23] - ID: 1262118447648997381)\n",
      "Processing Tweet# 23 - TopN [21] - ID: 1262820432010502146)\n",
      "Processing Tweet# 24 - TopN [4] - ID: 1264546699214827520)\n",
      "Processing Tweet# 25 - TopN [12] - ID: 1264558526640332800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/cdc_userstreams_top_25_retweeted_2020-06-09.json...Read 57,572 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/cdc.html\n"
     ]
    }
   ],
   "source": [
    "# Do some testing?\n",
    "# full_run('/home/jupyter/data/www/covid19-static-pages/configs/covid-maps.yaml')\n",
    "\n",
    "x = full_run('/home/jupyter/data/www/covid19-static-pages/configs/cdc.yaml', query=True, plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each configuration and do a full run\n",
    "\n",
    "Loading from `/home/jupyter/data/www/covid19-static-pages/configs/`\n",
    "\n",
    "Be sure to set `query=True` if we actually need to run the update; but let's only do that weekly because of cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 configurations\n"
     ]
    }
   ],
   "source": [
    "pages = glob.glob(STATIC_PAGES_ROOT + \"/configs/*.yaml\")\n",
    "print(\"Found {} configurations\".format(len(pages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/cdc-keywords.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying for top 25 retweets in cdc...done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [18] - ID: 1239964479544156161)\n",
      "Processing Tweet# 2 - TopN [12] - ID: 1240317386059853825)\n",
      "Processing Tweet# 3 - TopN [5] - ID: 1240380132226928640)\n",
      "Processing Tweet# 4 - TopN [13] - ID: 1240567553249824769)\n",
      "Processing Tweet# 5 - TopN [10] - ID: 1240669719595831296)\n",
      "Processing Tweet# 6 - TopN [20] - ID: 1241183544849969153)\n",
      "Processing Tweet# 7 - TopN [2] - ID: 1241367245143642113)\n",
      "Processing Tweet# 8 - TopN [19] - ID: 1241883781293920256)\n",
      "Processing Tweet# 9 - TopN [17] - ID: 1241910439841234945)\n",
      "Processing Tweet# 10 - TopN [8] - ID: 1243304246759559174)\n",
      "Processing Tweet# 11 - TopN [7] - ID: 1243592209418592258)\n",
      "Processing Tweet# 12 - TopN [22] - ID: 1243915217689612288)\n",
      "Processing Tweet# 13 - TopN [3] - ID: 1244056534583312384)\n",
      "Processing Tweet# 14 - TopN [23] - ID: 1244263133516095488)\n",
      "Processing Tweet# 15 - TopN [9] - ID: 1246128671372558336)\n",
      "Processing Tweet# 16 - TopN [11] - ID: 1246891081612103685)\n",
      "Processing Tweet# 17 - TopN [24] - ID: 1252306443497353218)\n",
      "Processing Tweet# 18 - TopN [14] - ID: 1253369453796118536)\n",
      "Processing Tweet# 19 - TopN [16] - ID: 1254461728575967232)\n",
      "Processing Tweet# 20 - TopN [6] - ID: 1258765736207671297)\n",
      "Processing Tweet# 21 - TopN [15] - ID: 1259291786897502209)\n",
      "Processing Tweet# 22 - TopN [21] - ID: 1260094985233367040)\n",
      "Processing Tweet# 23 - TopN [1] - ID: 1262804026355310592)\n",
      "Processing Tweet# 24 - TopN [25] - ID: 1263890792411729920)\n",
      "Processing Tweet# 25 - TopN [4] - ID: 1263977286761697280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/cdc_top_25_retweeted_2020-06-16.json...Read 255,589 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/cdc-keyword.html\n",
      "Querying for top 25 retweets in covid_maps..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/covid-maps.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [11] - ID: 1247525392904118274)\n",
      "Processing Tweet# 2 - TopN [12] - ID: 1247981587204935681)\n",
      "Processing Tweet# 3 - TopN [22] - ID: 1248356504924753925)\n",
      "Processing Tweet# 4 - TopN [25] - ID: 1248812705634373635)\n",
      "Processing Tweet# 5 - TopN [23] - ID: 1251104709844234240)\n",
      "Processing Tweet# 6 - TopN [4] - ID: 1251238755819814912)\n",
      "Processing Tweet# 7 - TopN [13] - ID: 1252058477054308353)\n",
      "Processing Tweet# 8 - TopN [5] - ID: 1252975821133840384)\n",
      "Processing Tweet# 9 - TopN [10] - ID: 1253298630884241409)\n",
      "Processing Tweet# 10 - TopN [21] - ID: 1255077875885187072)\n",
      "Processing Tweet# 11 - TopN [17] - ID: 1255086086281281538)\n",
      "Processing Tweet# 12 - TopN [6] - ID: 1255086554579525634)\n",
      "Processing Tweet# 13 - TopN [20] - ID: 1255128464274763788)\n",
      "Processing Tweet# 14 - TopN [14] - ID: 1255487754890285056)\n",
      "Processing Tweet# 15 - TopN [16] - ID: 1256220002245652480)\n",
      "Processing Tweet# 16 - TopN [19] - ID: 1260571831657996305)\n",
      "Processing Tweet# 17 - TopN [3] - ID: 1263134815538331655)\n",
      "Processing Tweet# 18 - TopN [18] - ID: 1263329713688215552)\n",
      "Processing Tweet# 19 - TopN [24] - ID: 1263908935452577793)\n",
      "Processing Tweet# 20 - TopN [8] - ID: 1264570617946345475)\n",
      "Processing Tweet# 21 - TopN [7] - ID: 1265120191295492097)\n",
      "Processing Tweet# 22 - TopN [15] - ID: 1265224762621669378)\n",
      "Processing Tweet# 23 - TopN [9] - ID: 1265289786404868096)\n",
      "Processing Tweet# 24 - TopN [2] - ID: 1269370851142615040)\n",
      "Processing Tweet# 25 - TopN [1] - ID: 1272334627194105856)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/covid-maps_top_25_retweeted_2020-06-16.json...Read 112,082 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/covid-maps.html\n",
      "Querying for top 25 retweets in covid_charts_and_graphics..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/covid-charts.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [19] - ID: 1243606217567744000)\n",
      "Processing Tweet# 2 - TopN [12] - ID: 1244567505177210880)\n",
      "Processing Tweet# 3 - TopN [14] - ID: 1245467940390133760)\n",
      "Processing Tweet# 4 - TopN [5] - ID: 1251105543248363522)\n",
      "Processing Tweet# 5 - TopN [1] - ID: 1251792857284751360)\n",
      "Processing Tweet# 6 - TopN [7] - ID: 1251809060497829888)\n",
      "Processing Tweet# 7 - TopN [8] - ID: 1252998685346148358)\n",
      "Processing Tweet# 8 - TopN [6] - ID: 1253033795642671107)\n",
      "Processing Tweet# 9 - TopN [13] - ID: 1253044684789886977)\n",
      "Processing Tweet# 10 - TopN [15] - ID: 1255236263097126912)\n",
      "Processing Tweet# 11 - TopN [23] - ID: 1255880290179956736)\n",
      "Processing Tweet# 12 - TopN [11] - ID: 1257265014618173440)\n",
      "Processing Tweet# 13 - TopN [18] - ID: 1259598334010036224)\n",
      "Processing Tweet# 14 - TopN [20] - ID: 1259625130512318464)\n",
      "Processing Tweet# 15 - TopN [9] - ID: 1260610012130545665)\n",
      "Processing Tweet# 16 - TopN [22] - ID: 1260976692375564290)\n",
      "Processing Tweet# 17 - TopN [24] - ID: 1261679137498058754)\n",
      "Processing Tweet# 18 - TopN [10] - ID: 1262012536968396801)\n",
      "Processing Tweet# 19 - TopN [3] - ID: 1262029906512404480)\n",
      "Processing Tweet# 20 - TopN [4] - ID: 1262048219799990273)\n",
      "Processing Tweet# 21 - TopN [16] - ID: 1262780055136206855)\n",
      "Processing Tweet# 22 - TopN [25] - ID: 1263188304930930689)\n",
      "Processing Tweet# 23 - TopN [17] - ID: 1265870923371958273)\n",
      "Processing Tweet# 24 - TopN [21] - ID: 1266104311890808832)\n",
      "Processing Tweet# 25 - TopN [2] - ID: 1272254390791962632)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/covid-charts_top_25_retweeted_2020-06-16.json...Read 192,443 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/covid-charts.html\n",
      "Querying for top 25 retweets in cdc_userstreams..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/cdc.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [3] - ID: 1252632573798473731)\n",
      "Processing Tweet# 2 - TopN [11] - ID: 1252993080174796800)\n",
      "Processing Tweet# 3 - TopN [8] - ID: 1253085285161803777)\n",
      "Processing Tweet# 4 - TopN [6] - ID: 1253341609443250176)\n",
      "Processing Tweet# 5 - TopN [15] - ID: 1253374836317044736)\n",
      "Processing Tweet# 6 - TopN [2] - ID: 1253422154256756738)\n",
      "Processing Tweet# 7 - TopN [13] - ID: 1253468948068290560)\n",
      "Processing Tweet# 8 - TopN [14] - ID: 1253705772569067520)\n",
      "Processing Tweet# 9 - TopN [1] - ID: 1253742258853199872)\n",
      "Processing Tweet# 10 - TopN [7] - ID: 1253793094841090056)\n",
      "Processing Tweet# 11 - TopN [10] - ID: 1253818998942314496)\n",
      "Processing Tweet# 12 - TopN [18] - ID: 1254129055219298308)\n",
      "Processing Tweet# 13 - TopN [17] - ID: 1254857606859898881)\n",
      "Processing Tweet# 14 - TopN [22] - ID: 1255971941019762694)\n",
      "Processing Tweet# 15 - TopN [5] - ID: 1256309675269615616)\n",
      "Processing Tweet# 16 - TopN [24] - ID: 1256655451195715585)\n",
      "Processing Tweet# 17 - TopN [16] - ID: 1261044372621189120)\n",
      "Processing Tweet# 18 - TopN [9] - ID: 1261406011039993856)\n",
      "Processing Tweet# 19 - TopN [19] - ID: 1262052014973911041)\n",
      "Processing Tweet# 20 - TopN [25] - ID: 1262118447648997381)\n",
      "Processing Tweet# 21 - TopN [23] - ID: 1262820432010502146)\n",
      "Processing Tweet# 22 - TopN [4] - ID: 1264546699214827520)\n",
      "Processing Tweet# 23 - TopN [12] - ID: 1264558526640332800)\n",
      "Processing Tweet# 24 - TopN [21] - ID: 1271533487665881088)\n",
      "Processing Tweet# 25 - TopN [20] - ID: 1272576006528946180)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/cdc_userstreams_top_25_retweeted_2020-06-16.json...Read 58,174 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/cdc.html\n",
      "Querying for top 10 retweets in donald_trump..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/trump.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [4] - ID: 1259561821289226248)\n",
      "Processing Tweet# 2 - TopN [8] - ID: 1260735992727769096)\n",
      "Processing Tweet# 3 - TopN [5] - ID: 1262361817373958145)\n",
      "Processing Tweet# 4 - TopN [2] - ID: 1266354084036194306)\n",
      "Processing Tweet# 5 - TopN [1] - ID: 1267129644228247552)\n",
      "Processing Tweet# 6 - TopN [7] - ID: 1267515702652678144)\n",
      "Processing Tweet# 7 - TopN [10] - ID: 1267609190140436481)\n",
      "Processing Tweet# 8 - TopN [3] - ID: 1267992040010285057)\n",
      "Processing Tweet# 9 - TopN [9] - ID: 1268497685553823745)\n",
      "Processing Tweet# 10 - TopN [6] - ID: 1268671097010094082)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/trump_top_10_retweeted_2020-06-16.json...Read 927,204 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,] done\n",
      "Plotting top 10 [..........] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/trump.html\n",
      "Querying for top 25 retweets in us_governors..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/us_governors.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [20] - ID: 1253356421577654273)\n",
      "Processing Tweet# 2 - TopN [18] - ID: 1253358477415788548)\n",
      "Processing Tweet# 3 - TopN [4] - ID: 1253729749177970689)\n",
      "Processing Tweet# 4 - TopN [13] - ID: 1253784682262650881)\n",
      "Processing Tweet# 5 - TopN [25] - ID: 1256982073195343878)\n",
      "Processing Tweet# 6 - TopN [11] - ID: 1258404381722017793)\n",
      "Processing Tweet# 7 - TopN [15] - ID: 1258879674437914624)\n",
      "Processing Tweet# 8 - TopN [10] - ID: 1260273563275231234)\n",
      "Processing Tweet# 9 - TopN [5] - ID: 1262257093031202816)\n",
      "Processing Tweet# 10 - TopN [23] - ID: 1262776230786580480)\n",
      "Processing Tweet# 11 - TopN [8] - ID: 1263163614971588608)\n",
      "Processing Tweet# 12 - TopN [16] - ID: 1263190873908621316)\n",
      "Processing Tweet# 13 - TopN [6] - ID: 1263814853921251333)\n",
      "Processing Tweet# 14 - TopN [2] - ID: 1264558205683843073)\n",
      "Processing Tweet# 15 - TopN [17] - ID: 1264924734472491009)\n",
      "Processing Tweet# 16 - TopN [3] - ID: 1266036686053613574)\n",
      "Processing Tweet# 17 - TopN [24] - ID: 1266765209391284225)\n",
      "Processing Tweet# 18 - TopN [1] - ID: 1267602763875332096)\n",
      "Processing Tweet# 19 - TopN [7] - ID: 1267849178920689669)\n",
      "Processing Tweet# 20 - TopN [21] - ID: 1268207359098269696)\n",
      "Processing Tweet# 21 - TopN [22] - ID: 1268208644618936321)\n",
      "Processing Tweet# 22 - TopN [14] - ID: 1268644990034612225)\n",
      "Processing Tweet# 23 - TopN [19] - ID: 1268992126190157825)\n",
      "Processing Tweet# 24 - TopN [9] - ID: 1270383187554971648)\n",
      "Processing Tweet# 25 - TopN [12] - ID: 1270941712320352258)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/us_governors_top_25_retweeted_2020-06-16.json...Read 578,243 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/us-governors.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/covid-data.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying for top 25 retweets in covid_data_representations...done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [13] - ID: 1244382336533266432)\n",
      "Processing Tweet# 2 - TopN [23] - ID: 1245612562730737667)\n",
      "Processing Tweet# 3 - TopN [16] - ID: 1246629670570901504)\n",
      "Processing Tweet# 4 - TopN [15] - ID: 1247191480835485698)\n",
      "Processing Tweet# 5 - TopN [5] - ID: 1247291781978431489)\n",
      "Processing Tweet# 6 - TopN [20] - ID: 1247917397400526848)\n",
      "Processing Tweet# 7 - TopN [14] - ID: 1251352745824550912)\n",
      "Processing Tweet# 8 - TopN [7] - ID: 1252239099198672899)\n",
      "Processing Tweet# 9 - TopN [11] - ID: 1253455078071173128)\n",
      "Processing Tweet# 10 - TopN [19] - ID: 1254461123753054209)\n",
      "Processing Tweet# 11 - TopN [18] - ID: 1257096834218168321)\n",
      "Processing Tweet# 12 - TopN [24] - ID: 1257437963467862019)\n",
      "Processing Tweet# 13 - TopN [10] - ID: 1260359025704800264)\n",
      "Processing Tweet# 14 - TopN [6] - ID: 1262208199152881664)\n",
      "Processing Tweet# 15 - TopN [17] - ID: 1262569508553752579)\n",
      "Processing Tweet# 16 - TopN [4] - ID: 1262589109517733888)\n",
      "Processing Tweet# 17 - TopN [12] - ID: 1263468300069191680)\n",
      "Processing Tweet# 18 - TopN [21] - ID: 1265125472284917761)\n",
      "Processing Tweet# 19 - TopN [9] - ID: 1265885480144470023)\n",
      "Processing Tweet# 20 - TopN [2] - ID: 1270120241897410560)\n",
      "Processing Tweet# 21 - TopN [8] - ID: 1271213057059020808)\n",
      "Processing Tweet# 22 - TopN [22] - ID: 1271217385538756611)\n",
      "Processing Tweet# 23 - TopN [25] - ID: 1271881202836934657)\n",
      "Processing Tweet# 24 - TopN [3] - ID: 1272334627194105856)\n",
      "Processing Tweet# 25 - TopN [1] - ID: 1272404064106676226)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/covid-data_top_25_retweeted_2020-06-16.json...Read 445,289 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/covid-data.html\n",
      "Querying for top 25 retweets in world_health_organization..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/who.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done; creating dataframe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Tweet# 1 - TopN [6] - ID: 1250555076156043264)\n",
      "Processing Tweet# 2 - TopN [8] - ID: 1250938650310914049)\n",
      "Processing Tweet# 3 - TopN [21] - ID: 1251191291381080064)\n",
      "Processing Tweet# 4 - TopN [16] - ID: 1251454794260189184)\n",
      "Processing Tweet# 5 - TopN [4] - ID: 1251571221998653440)\n",
      "Processing Tweet# 6 - TopN [24] - ID: 1252257397793423360)\n",
      "Processing Tweet# 7 - TopN [13] - ID: 1252260563343880194)\n",
      "Processing Tweet# 8 - TopN [10] - ID: 1253034861033656320)\n",
      "Processing Tweet# 9 - TopN [2] - ID: 1253464496443658249)\n",
      "Processing Tweet# 10 - TopN [17] - ID: 1253917386371104769)\n",
      "Processing Tweet# 11 - TopN [1] - ID: 1253995619921821698)\n",
      "Processing Tweet# 12 - TopN [11] - ID: 1254160937805926405)\n",
      "Processing Tweet# 13 - TopN [23] - ID: 1254897255292776457)\n",
      "Processing Tweet# 14 - TopN [25] - ID: 1255609083446657024)\n",
      "Processing Tweet# 15 - TopN [20] - ID: 1255935908978794497)\n",
      "Processing Tweet# 16 - TopN [18] - ID: 1257586848198688768)\n",
      "Processing Tweet# 17 - TopN [15] - ID: 1257937948424757248)\n",
      "Processing Tweet# 18 - TopN [7] - ID: 1258730767548645376)\n",
      "Processing Tweet# 19 - TopN [14] - ID: 1260128088849031168)\n",
      "Processing Tweet# 20 - TopN [22] - ID: 1262323297863168000)\n",
      "Processing Tweet# 21 - TopN [19] - ID: 1265674953816518658)\n",
      "Processing Tweet# 22 - TopN [12] - ID: 1266856688998645768)\n",
      "Processing Tweet# 23 - TopN [3] - ID: 1267506298477838337)\n",
      "Processing Tweet# 24 - TopN [5] - ID: 1268462539551191042)\n",
      "Processing Tweet# 25 - TopN [9] - ID: 1268986094042992640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /home/jupyter/data/diffusion/who_top_25_retweeted_2020-06-16.json...Read 65,833 retweets\n",
      "Discounting self-retweets: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,] done\n",
      "Plotting top 25 [.........................] Done\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/who.html\n"
     ]
    }
   ],
   "source": [
    "for configuration_file in pages:\n",
    "    x = full_run(configuration_file, query=True, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><hr><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be sure to run the following command to copy the data files to Google buckets:\n",
      "\n",
      "\n",
      "gsutil -m cp -r /home/jupyter/data/www/covid19-static-pages/docs/data gs://epic-covid19/diffusion-graphs/\n"
     ]
    }
   ],
   "source": [
    "print(\"Be sure to run the following command to copy the data files to Google buckets:\\n\\n\")\n",
    "print(\"gsutil -m cp -r /home/jupyter/data/www/covid19-static-pages/docs/data gs://epic-covid19/diffusion-graphs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
