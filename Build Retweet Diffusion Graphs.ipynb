{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystache, plotly, json, random, sys, yaml, glob, os\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creates Interactive Diffusion Graphs\n",
    "\n",
    "1. Reads yaml configuration files from `/home/jupyter/data/www/covid19-static-pages/configs`\n",
    "2. Queries for retweets from Big Query\n",
    "3. Processes and produces simplified JSON output of retweets.\n",
    "3. Reads simplified JSON into Plotly and writes JSON configurations for Plotly Graphs and HTML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    '/home/jupyter/covid-19-data/.credentials/google-connector.json')\n",
    "project_id = 'crypto-eon-164220'\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get top retweets from Big Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_N_retweeted_tweets(table, N=25):\n",
    "    sys.stderr.write(\"Querying for top {} retweets in {}...\".format(N, table))\n",
    "    \n",
    "    query_job = client.query(\"\"\"\n",
    "SELECT\n",
    "  id AS retweet_id,\n",
    "  min(original_tweet_id) AS orig_id,\n",
    "  min(tweet_text) AS orig_text,\n",
    "  min(times_retweeted_) AS times_retweeted,\n",
    "  min(original_author) AS orig_author,\n",
    "  min(original_followers) as orig_followers_count,\n",
    "  min(original_posted) AS orig_posted,\n",
    "  min(user.screen_name) AS retweeter,\n",
    "  min(user.followers_count) AS retweeter_followers_count,\n",
    "  min(PARSE_TIMESTAMP('%a %b %d %T %z %Y', created_at)) AS retweet_timestamp\n",
    "FROM\n",
    "  `crypto-eon-164220.tweets.{TABLE}` tweets,\n",
    "  (\n",
    "  SELECT\n",
    "    MIN(retweeted_status.id) AS original_tweet_id,\n",
    "    MIN(retweeted_status.text) AS tweet_text,\n",
    "    MIN(retweeted_status.user.screen_name) AS original_author,\n",
    "    MIN(retweeted_status.user.followers_count) AS original_followers,\n",
    "    MIN(PARSE_TIMESTAMP('%a %b %d %T %z %Y', retweeted_status.created_at)) AS original_posted,\n",
    "    COUNT(DISTINCT(id)) AS times_retweeted_\n",
    "  FROM\n",
    "    `crypto-eon-164220.tweets.{TABLE}`\n",
    "  WHERE\n",
    "    retweeted_status IS NOT NULL\n",
    "    AND retweeted_status.id >= (SELECT MIN(id) FROM `crypto-eon-164220.tweets.{TABLE}`)\n",
    "  GROUP BY\n",
    "    retweeted_status.id\n",
    "  ORDER BY times_retweeted_ DESC\n",
    "  LIMIT {N}\n",
    "  ) topRetweets\n",
    "WHERE\n",
    "  topRetweets.original_tweet_id = tweets.retweeted_status.id\n",
    "GROUP by id\n",
    "order by orig_id\n",
    "\"\"\".format(TABLE=table,\n",
    "           N=N) )\n",
    "    \n",
    "    sys.stderr.write(\"done; creating dataframe\\n\")\n",
    "    return query_job.result().to_dataframe()\n",
    "\n",
    "def get_tweets_retweeted_more_than_X_times(table, threshold=2000):\n",
    "    sys.stderr.write(\"Querying for tweets retweeted more than {} times in {}...\".format(threshold, table))\n",
    "    \n",
    "    query_job = client.query(\"\"\"\n",
    "SELECT\n",
    "  id AS retweet_id,\n",
    "  min(original_tweet_id) AS orig_id,\n",
    "  min(tweet_text) AS orig_text,\n",
    "  min(times_retweeted_) AS times_retweeted,\n",
    "  min(original_author) AS orig_author,\n",
    "  min(original_followers) as orig_followers_count,\n",
    "  min(original_posted) AS orig_posted,\n",
    "  min(user.screen_name) AS retweeter,\n",
    "  min(user.followers_count) AS retweeter_followers_count,\n",
    "  min(PARSE_TIMESTAMP('%a %b %d %T %z %Y', created_at)) AS retweet_timestamp\n",
    "FROM\n",
    "  `crypto-eon-164220.tweets.{TABLE}` tweets,\n",
    "  (\n",
    "  SELECT\n",
    "    MIN(retweeted_status.id) AS original_tweet_id,\n",
    "    MIN(retweeted_status.text) AS tweet_text,\n",
    "    MIN(retweeted_status.user.screen_name) AS original_author,\n",
    "    MIN(retweeted_status.user.followers_count) AS original_followers,\n",
    "    MIN(PARSE_TIMESTAMP('%a %b %d %T %z %Y', retweeted_status.created_at)) AS original_posted,\n",
    "    COUNT(DISTINCT(id)) AS times_retweeted_\n",
    "  FROM\n",
    "    `crypto-eon-164220.tweets.{TABLE}`\n",
    "  WHERE\n",
    "    retweeted_status IS NOT NULL\n",
    "    AND retweeted_status.id >= (SELECT MIN(id) FROM `crypto-eon-164220.tweets.{TABLE}`)\n",
    "  GROUP BY\n",
    "    retweeted_status.id\n",
    "  ORDER BY times_retweeted_ DESC\n",
    "  ) topRetweets\n",
    "WHERE\n",
    "  topRetweets.original_tweet_id = tweets.retweeted_status.id\n",
    "  AND topRetweets.times_retweeted_ > {TIMES_RETWEETED_THRESHOLD} \n",
    "GROUP by id\n",
    "order by orig_id\n",
    "\"\"\".format(TABLE=table,\n",
    "           TIMES_RETWEETED_THRESHOLD=threshold) )\n",
    "    \n",
    "    sys.stderr.write(\"done; creating dataframe\\n\")\n",
    "    return query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_for_plotly(df, fileName):\n",
    "\n",
    "    retweet_counts_by_id = list(df.orig_id.value_counts(ascending=False).keys())\n",
    "\n",
    "    count = 0;\n",
    "    to_return = pd.DataFrame()\n",
    "\n",
    "    for original_id, retweets in df.groupby('orig_id'):\n",
    "        count += 1;\n",
    "        topN = retweet_counts_by_id.index(original_id) + 1 # The Top N tweet...\n",
    "        print(\"Processing Tweet# {} - TopN [{}] - ID: {})\".format(count, topN, original_id))\n",
    "\n",
    "        sorted_retweets = retweets.sort_values(by='retweet_id').reindex()\n",
    "\n",
    "        original_tweet = pd.DataFrame([{\n",
    "            'id': sorted_retweets.iloc[0].orig_id,\n",
    "            'created_at': sorted_retweets.iloc[0].orig_posted,\n",
    "            'username': sorted_retweets.iloc[0].orig_author,\n",
    "            'followers_count': sorted_retweets.iloc[0].orig_followers_count\n",
    "        }])\n",
    "\n",
    "        text = sorted_retweets.iloc[0].orig_text\n",
    "\n",
    "        interested_rows = sorted_retweets[['retweet_id','retweet_timestamp','retweeter','retweeter_followers_count']]\n",
    "        interested_rows.columns = ['id','created_at','username','followers_count']\n",
    "\n",
    "        #Add the first row for the original tweet\n",
    "        x = pd.concat([original_tweet, interested_rows]).reset_index(drop = True) \n",
    "\n",
    "        x['followers_count_cumsum'] = x.followers_count.cumsum()\n",
    "        x['text'] = text\n",
    "        x['top_N'] = topN\n",
    "        \n",
    "        x.created_at = x.created_at.apply(lambda x: x.isoformat())\n",
    "\n",
    "        to_return = pd.concat([x, to_return])\n",
    "\n",
    "    current_datestamp = datetime.today().strftime('%Y-%m-%d')\n",
    "    with open(fileName +\"_\"+current_datestamp+'.json','w') as f:\n",
    "        json.dump(to_return.sort_values(by='top_N').to_dict('records'), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(config):\n",
    "    \n",
    "    df = get_top_N_retweeted_tweets(config['table'], N= (config.get(\"topN\") or 10) )\n",
    "    \n",
    "    create_dataframe_for_plotly(df, config['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = plotly.colors.qualitative.Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_colors():\n",
    "    sns.palplot(COLORS)\n",
    "\n",
    "def normalize(values, desired_bounds):\n",
    "    actual_bounds = (min(values), max(values))\n",
    "    result = [desired_bounds[0] + (x - actual_bounds[0]) *\n",
    "            (desired_bounds[1] - desired_bounds[0]) / \\\n",
    "            (actual_bounds[1] - actual_bounds[0]) for x in values]\n",
    "    return [round(x,2) for x in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the latest diffusion data...\n",
    "def read_dataframe_from_file(CONFIG):\n",
    "\n",
    "    #Get the latest file\n",
    "    latest_file = sorted(glob.glob(CONFIG['data']+\"*.json\"))[-1]\n",
    "    \n",
    "    sys.stderr.write(\"Loading \"+latest_file+\"...\")\n",
    "    to_plot = json.load(open(latest_file,'r')) #Could put error handling here if necessary\n",
    "\n",
    "    df = pd.DataFrame(to_plot)\n",
    "    df['timestamp'] = df.created_at.apply(lambda t: pd.Timestamp(t))\n",
    "    sys.stderr.write((\"Read {:,} retweets\\n\".format(len(to_plot))))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_self_retweets(input_df):\n",
    "\n",
    "    sys.stderr.write(\"Discounting self-retweets: [\")\n",
    "    df = pd.DataFrame.copy(input_df, deep=True)\n",
    "    \n",
    "    tweet_data = {}\n",
    "\n",
    "    for topN in df.top_N.unique():\n",
    "        newCounter = 0\n",
    "        subValue = 0\n",
    "        for idx, row in df[df.top_N == topN].sort_values(by='id').iterrows():\n",
    "            if newCounter==0:\n",
    "                thisUser = row.username\n",
    "                origFollowerCount = row.followers_count\n",
    "                origTweetID = str(row.id)\n",
    "                tweet_data[str(topN)] = {\n",
    "                    'text' : row.text,\n",
    "                    'user' : thisUser,\n",
    "                    'rank' : int(topN),\n",
    "                    'color': COLORS[topN%len(COLORS)],\n",
    "                    'id'   : origTweetID,\n",
    "                    'self-rt' : [],\n",
    "                    'time' : row.timestamp.isoformat()\n",
    "                }\n",
    "            else:\n",
    "                if row.username == thisUser:\n",
    "                    if row.followers_count > origFollowerCount:\n",
    "                        subValue = origFollowerCount\n",
    "                    else:\n",
    "                        subValue = row.followers_count\n",
    "                    tweet_data[str(topN)]['self-rt'].append(\n",
    "#                         \"2020-04-19T01:53:07+00:00\"\n",
    "                        {'x':row.timestamp.isoformat(), 'subValue':subValue}\n",
    "                    )                    \n",
    "            if subValue > 0:\n",
    "                df.loc[idx,'followers_count_cumsum'] = row.followers_count_cumsum - subValue\n",
    "            newCounter += 1;\n",
    "        sys.stderr.write(\"{},\".format(topN))\n",
    "        \n",
    "    sys.stderr.write(\"] done\\n\".format(topN))\n",
    "    \n",
    "    return (df, tweet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_label(row):\n",
    "    return \"{}: {} followers\".format(row.username, row.followers_count)\n",
    "\n",
    "def buildPlotlyGraph(df, topN=25):\n",
    "    sys.stderr.write(\"Plotting top {} [\".format(topN))\n",
    "    \n",
    "#     df['globalScaledMarker'] = df.followers_count.apply(lambda x: np.log2(x+1))\n",
    "    df['globalScaledMarker'] = normalize(list(df.followers_count), (10,100))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for topNidx in range(1,topN+1):\n",
    "\n",
    "        #Should be sorted safely?\n",
    "        plot_df = df[df.top_N==topNidx].sort_values(by='id')\n",
    "\n",
    "        if len(plot_df) > 0:\n",
    "\n",
    "            tweetId   = str(plot_df.head(1).id.values[0])\n",
    "            tweetText = plot_df.head(1).text.values[0]\n",
    "\n",
    "            if pd.isna(tweetText):\n",
    "                raise \"No Tweet Text on First Entry\"\n",
    "\n",
    "            color = COLORS[topNidx%len(COLORS)]\n",
    "\n",
    "            fig.add_trace(go.Scattergl(\n",
    "                name = str(topNidx), #rank\n",
    "                x    = plot_df.timestamp, \n",
    "                y    = plot_df.followers_count_cumsum,\n",
    "                mode = 'markers+lines',\n",
    "                marker = dict(\n",
    "                    size  = plot_df.globalScaledMarker, #normalize(list(plot_df.followers_count), (10,35)),\n",
    "                    color = color,\n",
    "                    opacity = 0.5,\n",
    "                    line=dict(\n",
    "                        color='white',\n",
    "                        width=0.4\n",
    "                    ),\n",
    "                ),\n",
    "                line=dict(\n",
    "                    color=color,\n",
    "                    width=0.75,\n",
    "                ),\n",
    "                hovertemplate ='%{x} - %{text}',\n",
    "                text = list(plot_df.apply(lambda row: custom_label(row), axis=1)),\n",
    "                meta={'u':plot_df.username,\n",
    "                      'f':plot_df.followers_count },\n",
    "                showlegend = True\n",
    "            ))\n",
    "            sys.stderr.write(\".\")\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1400,\n",
    "        height=600,\n",
    "        margin=dict(\n",
    "            t=1,r=50,l=1,b=1\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            traceorder=\"normal\",\n",
    "            font=dict(\n",
    "                family=\"sans-serif\",\n",
    "                size=12,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "    ),\n",
    "        yaxis_title=\"Potential Audience Exposure\",)\n",
    "\n",
    "    sys.stderr.write(\"] Done\\n\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For testing (initialize all below functions first (ah, jupyter)): \n",
    "# # c = full_run('/home/jupyter/data/www/covid19-static-pages/configs/cdc.yaml', query=False)\n",
    "\n",
    "# # Then change the function as much as needed and access with:\n",
    "# fig = buildPlotlyGraph(c['no_self_retweets'], (c.get('TopN') or 25))\n",
    "# # fig.show()\n",
    "\n",
    "# #Or write the JSON\n",
    "# figJSON = json.loads(plotly.io.to_json(fig))\n",
    "# figJSON['tweets'] = c['tweets']\n",
    "# with open(STATIC_PAGES_ROOT +\"/docs/\"+ c['JSON'],'w') as outFile: \n",
    "#     json.dump(figJSON, outFile)\n",
    "# buildSingleStaticPlotlyPage(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildSingleStaticPlotlyPage(CONFIG):\n",
    "    sys.stderr.write(\"Writing HTML... \")\n",
    "\n",
    "    main_template = open(STATIC_PAGES_ROOT + '/templates/plotly_js_template.html').read()\n",
    "\n",
    "    with open(STATIC_PAGES_ROOT + \"/\" + CONFIG['output'],'w') as outFile:\n",
    "        outFile.write(pystache.render(main_template, CONFIG))\n",
    "    sys.stderr.write(\" view at: http://epic.tweetsonamap.com/covid19-static-pages/\"+CONFIG['output']+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><hr><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runtime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES?\n",
    "STATIC_PAGES_ROOT = '/home/jupyter/data/www/covid19-static-pages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_run(yaml_config, query=True, plot=True, write_html=True):\n",
    "    print(\"Building page for: {}\".format(yaml_config))\n",
    "    config = yaml.load(open(yaml_config,'r'),\n",
    "                       Loader=yaml.FullLoader)\n",
    "    \n",
    "    if query:\n",
    "        get_data(config)\n",
    "    \n",
    "    if plot:\n",
    "        config['df'] = read_dataframe_from_file(config)\n",
    "    \n",
    "        topN = config.get('topN') or 25\n",
    "    \n",
    "        config['no_self_retweets'], config['tweets'] = calculate_self_retweets(config['df'] )\n",
    "\n",
    "        config['fig'] = buildPlotlyGraph(config['no_self_retweets'], topN=topN)\n",
    "    \n",
    "        figJSON = json.loads(plotly.io.to_json(config['fig']))\n",
    "        figJSON['tweets'] = config['tweets']\n",
    "        \n",
    "        with open(STATIC_PAGES_ROOT +\"/docs/\"+ config['JSON'],'w') as outFile: \n",
    "            json.dump(figJSON, outFile)\n",
    "            \n",
    "    if write_html:\n",
    "        buildSingleStaticPlotlyPage(config)\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some testing?\n",
    "# full_run('/home/jupyter/data/www/covid19-static-pages/configs/covid-maps.yaml')\n",
    "\n",
    "# x = full_run('/home/jupyter/data/www/covid19-static-pages/configs/who.yaml', query=False, plot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each configuration and do a full run\n",
    "\n",
    "Loading from `/home/jupyter/data/www/covid19-static-pages/configs/`\n",
    "\n",
    "Be sure to set `query=True` if we actually need to run the update; but let's only do that weekly because of cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 configurations\n"
     ]
    }
   ],
   "source": [
    "pages = glob.glob(STATIC_PAGES_ROOT + \"/configs/*.yaml\")\n",
    "print(\"Found {} configurations\".format(len(pages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/cdc-keywords.yaml\n",
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/covid-maps.yaml\n",
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/covid-charts.yaml\n",
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/cdc.yaml\n",
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/trump.yaml\n",
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/us_governors.yaml\n",
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/covid-data.yaml\n",
      "Building page for: /home/jupyter/data/www/covid19-static-pages/configs/who.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/cdc-keyword.html\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/covid-maps.html\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/covid-charts.html\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/cdc.html\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/trump.html\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/us-governors.html\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/covid-data.html\n",
      "Writing HTML...  view at: http://epic.tweetsonamap.com/covid19-static-pages/docs/who.html\n"
     ]
    }
   ],
   "source": [
    "for configuration_file in pages:\n",
    "    x = full_run(configuration_file, query=False, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><hr><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for configuration_file in pages:\n",
    "    x = full_run(configuration_file, query=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Be sure to run the following command to copy the data files to Google buckets:\n",
      "\n",
      "\n",
      "gsutil -m cp -r /home/jupyter/data/www/covid19-static-pages/docs/data gs://epic-covid19/diffusion-graphs/\n"
     ]
    }
   ],
   "source": [
    "print(\"Be sure to run the following command to copy the data files to Google buckets:\\n\\n\")\n",
    "print(\"gsutil -m cp -r /home/jupyter/data/www/covid19-static-pages/docs/data gs://epic-covid19/diffusion-graphs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
